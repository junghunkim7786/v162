---
title: Rotting Infinitely Many-Armed Bandits
booktitle: Proceedings of the 39th International Conference on Machine Learning
abstract: We consider the infinitely many-armed bandit problem with rotting rewards,
  where the mean reward of an arm decreases at each pull of the arm according to an
  arbitrary trend with maximum rotting rate $\rot=o(1)$. We show that this learning
  problem has an $\Omega(\max\{\rot^{1/3}T, \sqrt{T}\})$ worst-case regret lower bound
  where $T$ is the time horizon. We show that a matching upper bound $\tilde{O}(\max\{\rot^{1/3}T,
  \sqrt{T}\})$, up to a poly-logarithmic factor, can be achieved by an algorithm that
  uses a UCB index for each arm and a threshold value to decide whether to continue
  pulling an arm or remove the arm from further consideration, when the algorithm
  knows the value of the maximum rotting rate $\rot$. We also show that an $\tilde{O}(\max\{\rot^{1/3}T,
  T^{3/4}\})$ regret upper bound can be achieved by an algorithm that does not know
  the value of $\rot$, by using an adaptive UCB index along with an adaptive threshold
  value.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: kim22j
month: 0
tex_title: Rotting Infinitely Many-Armed Bandits
firstpage: 11229
lastpage: 11254
page: 11229-11254
order: 11229
cycles: false
bibtex_author: Kim, Jung-hun and Vojnovic, Milan and Yun, Se-Young
author:
- given: Jung-Hun
  family: Kim
- given: Milan
  family: Vojnovic
- given: Se-Young
  family: Yun
date: 2022-06-28
address:
container-title: Proceedings of the 39th International Conference on Machine Learning
volume: '162'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 6
  - 28
pdf: https://proceedings.mlr.press/v162/kim22j/kim22j.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
